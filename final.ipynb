{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load templates from a directory\n",
    "template_dir = 'templates/'\n",
    "templates = []\n",
    "template_names = []\n",
    "\n",
    "\n",
    "def load_templates(rf = 0.3):\n",
    "    #load templates\n",
    "    for template_file in os.listdir(template_dir):\n",
    "        template_path = os.path.join(template_dir, template_file)\n",
    "        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)  # Read the template in grayscale\n",
    "        template = cv2.resize(template, None, fx=rf, fy=rf)\n",
    "        template = cv2.flip(template, 1)\n",
    "        templates.append(template)\n",
    "        template_names.append(os.path.splitext(template_file)[0])\n",
    "\n",
    "def draw_ROI(background, original_image, original_frame, prev_cX):\n",
    "    #difference image\n",
    "    diff = cv2.absdiff(background, original_image)\n",
    "    #thresholded image\n",
    "    _, thresholded_diff = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    #contours\n",
    "    contours, _ = cv2.findContours(thresholded_diff, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ismoving = False\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # area = cv2.contourArea(largest_contour)\n",
    "        # if area<1000:\n",
    "        #     cv2.putText(original_frame, f'No Hand Detected', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "        #     continue\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        moments = cv2.moments(largest_contour)\n",
    "\n",
    "        cv2.rectangle(original_frame, (original_frame.shape[1]-300 + x, y), (original_frame.shape[1]-300 + x + w, y + h), (255,0,0), 2)            \n",
    "        if moments[\"m00\"]:\n",
    "            centroid_x = int(moments[\"m10\"] / moments[\"m00\"])\n",
    "            centroid_y = int(moments[\"m01\"] / moments[\"m00\"])\n",
    "                        # Check if the centroid has moved a lot horizontally\n",
    "            if abs(centroid_x - prev_cX) > 15 and moments[\"m00\"] != 0:\n",
    "                prev_cX= centroid_x\n",
    "                ismoving =  True\n",
    "\n",
    "            original_frame = cv2.circle(original_frame, (original_frame.shape[1]-300 +centroid_x, centroid_y), 5, 128, -1)\n",
    "            original_frame = cv2.putText(original_frame, f'Centroid', (original_frame.shape[1]-300 +centroid_x, centroid_y), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
    "\n",
    "    return original_frame, thresholded_diff, ismoving, prev_cX\n",
    "\n",
    "def classify(original_image, original_frame, ismoving):\n",
    "    # Initialize variables to keep track of the best match\n",
    "    best_match_value = -1\n",
    "    best_template_index = -1\n",
    "    best_scale_factor = 1.0\n",
    "\n",
    "    # Iterate through templates\n",
    "    for i, template in enumerate(templates):\n",
    "        # Initialize variables for the current template\n",
    "        template_best_match_value = -1\n",
    "        template_best_scale_factor = 1.0\n",
    "\n",
    "        # Iterate through different scales of the image\n",
    "        for scale_factor in np.linspace(0.1, 1.0, 10):\n",
    "            scaled_image = cv2.resize(original_image, None, fx=scale_factor, fy=scale_factor)\n",
    "            if scaled_image.shape[0]<template.shape[0] or scaled_image.shape[1]<template.shape[1]:\n",
    "                continue\n",
    "            result = cv2.matchTemplate(scaled_image, template, cv2.TM_CCOEFF_NORMED)\n",
    "            _, max_val, _, _ = cv2.minMaxLoc(result)\n",
    "\n",
    "            # Update the best match information for the current template\n",
    "            if max_val > template_best_match_value:\n",
    "                template_best_match_value = max_val\n",
    "                template_best_scale_factor = scale_factor\n",
    "\n",
    "        # Update the overall best match information\n",
    "        if template_best_match_value > best_match_value:\n",
    "            best_match_value = template_best_match_value\n",
    "            best_template_index = i\n",
    "            best_scale_factor = template_best_scale_factor\n",
    "\n",
    "    corr_threshold = 0.74\n",
    "    # Draw a rectangle around the matched template\n",
    "    if best_template_index != -1 and best_match_value>corr_threshold:\n",
    "        # Display the class label\n",
    "        class_label = template_names[best_template_index]\n",
    "        if ismoving:\n",
    "            if class_label == \"rock\":\n",
    "                cv2.putText(original_frame, f\"Don't hit me with that rock!\", (10, 70), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "            elif class_label == \"paper\":\n",
    "                cv2.putText(original_frame, f\"Bye!\", (10, 70), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(original_frame, f'Class: {class_label}', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "        cv2.putText(original_frame, f'corr: {best_match_value}', (10, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(original_frame, f'No Hand Detected', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "    return original_frame\n",
    "\n",
    "def main():\n",
    "    load_templates()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Couldn't open the webcam.\")\n",
    "        return\n",
    "    ret, background = cap.read()\n",
    "    prev_cX = 0\n",
    "    #set background\n",
    "    \n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Capture frame from webcam\n",
    "        ret, original_frame = cap.read()\n",
    "        original_frame = cv2.flip(original_frame, 1)\n",
    "        frame_count += 1\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read a frame from the webcam.\")\n",
    "            break\n",
    "        set_background_after = 60\n",
    "        if frame_count<set_background_after:\n",
    "            continue\n",
    "        if frame_count==set_background_after:\n",
    "            background = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)[:300,-300:]\n",
    "             \n",
    "        #Region to consider\n",
    "        roi = cv2.cvtColor(original_frame, cv2.COLOR_BGR2GRAY)[:300,-300:]\n",
    "        original_frame, thresholded_diff, is_moving, prev_cX = draw_ROI(background, roi,original_frame, prev_cX)\n",
    "        original_frame = classify(roi, original_frame, is_moving)\n",
    "        cv2.rectangle(original_frame, (original_frame.shape[1]-300, 0), (original_frame.shape[1], 300), (0,255,0), 2)\n",
    "        cv2.imshow('Template Matching', original_frame)\n",
    "        cv2.imshow('threshold', thresholded_diff)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q') :\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
